{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuring the API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Initialize the model with \"Gemini Pro\"\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAQO0z5cT16DMlx7eAeEz6JRetneZiezq4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing NLP tasks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fareed will arrive at 9:00 AM. He will meet you at the airport. He will be driving a black BMW. His license plate is 123-456-7890.\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import clean_text\n",
    "\n",
    "user_input = '''faree$$@$%d will arrive at 9:00 AM. He will@%$ 1meet you at the airport. \n",
    "                He will be driving a black BMW. His license plate is 123-456-7890.'''\n",
    "\n",
    "# question to be asked\n",
    "cleaned_text = clean_text(user_input, model)\n",
    "\n",
    "# generate response\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat be run and play in garden, while dog be bark loud and chase their tail.\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import lemmatize_text\n",
    "\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs are barking loudly and chasing their tails.'''\n",
    "\n",
    "lemmatized_sentence = lemmatize_text(user_input, model)\n",
    "\n",
    "print(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat run play garden dog bark loud chase tail\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import stem_text\n",
    "\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs \n",
    "                are barking loudly and chasing their tails'''\n",
    "\n",
    "stemmed_sentence = stem_text(user_input, model)\n",
    "\n",
    "print(stemmed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization of Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The, cats, are, running, and, playing, in, the, gardens, comma, while, the, dogs, are, barking, loudly, and, chasing, their, tails]\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import tokenize_text\n",
    "\n",
    "user_input = '''The cats are running and playing in the gardens, \n",
    "                while the dogs are barking loudly and chasing their \n",
    "                tails'''\n",
    "\n",
    "tokenized_text = tokenize_text(user_input, model)\n",
    "\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123-456-7890', '523-456-7892', 'x123@gmail.com', 'fareed khan']\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import extract_patterns\n",
    "\n",
    "user_input = '''The phone number of fareed khan is 123-456-7890 and 523-456-7892. \n",
    "                Please call for assistance and email me at x123@gmail.com'''\n",
    "\n",
    "pattern_matching = '''email, phone number, name'''\n",
    "\n",
    "extracted_pattern = extract_patterns(user_input, pattern_matching, model)\n",
    "\n",
    "print(extracted_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing HTML tags from Sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is bold and italic text.\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import remove_html_tags\n",
    "\n",
    "user_input = '''<p>This is <b>bold</b> and <i>italic</i> text.</p>'''\n",
    "\n",
    "html_tags = '''<p>, <b>, <i>''' \n",
    "\n",
    "removed_tag_text = remove_html_tags(user_input, html_tags, model)\n",
    "\n",
    "print(removed_tag_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like rabbits, but I don't like dogs.\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import replace_text\n",
    "\n",
    "user_input = '''I like cats, but I don't like dogs.'''\n",
    "\n",
    "replacement_rules = ''' all animals to rabbits'''\n",
    "\n",
    "replaced_text = replace_text(user_input, replacement_rules, model)\n",
    "\n",
    "print(replaced_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Vector Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0195884,\n",
       " 0.024218114,\n",
       " -0.029704109,\n",
       " -0.05665759,\n",
       " -0.011961627,\n",
       " -0.026998892,\n",
       " -0.024396203,\n",
       " -0.021466378,\n",
       " 0.021265924,\n",
       " -0.0027763597]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pre_processing import generate_embeddings\n",
    "\n",
    "user_input = [\"cats are running and playing in the gardens\", \"dogs are barking loudly and chasing their tails\"]\n",
    "\n",
    "embeddings = generate_embeddings(user_input)\n",
    "\n",
    "embeddings['embedding'][0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Core NLP Tasks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform following \"Text Classification\" tasks from now:\n",
    "1. Sentiment Analysis\n",
    "2. Topic Classification\n",
    "3. Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Neutral\n",
      "\n",
      "Explanation:\n",
      "\n",
      "The author of the text expresses both positive and negative sentiments. The author starts by saying that they love to play football, which is a positive sentiment. However, the author then says that they are feeling very sad today and do not want to play football, which is a negative sentiment. Overall, the text is neutral because the positive and negative sentiments cancel each other out.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import analyze_sentiment\n",
    "\n",
    "user_input = \"I love to play football, but today I am feeling very sad.I do not want to play football today.\"\n",
    "\n",
    "category = \"positive, negative, neutral\"\n",
    "\n",
    "sentiment_result = analyze_sentiment(input_text=user_input, category=category, explanation=True, model=model)\n",
    "print(sentiment_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: story\n",
      "short explanation: The text is about a person's feelings and their decision not to play football that day. It is a personal story.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import classify_topic\n",
    "\n",
    "user_input = \"I love to play football, but today I am feeling very sad.I do not want to play football today.\"\n",
    "\n",
    "topics = \"topics are: story, comedy, horror\"\n",
    "\n",
    "classified_result = classify_topic(input_text=user_input, topics=topics, explanation=True, model=model)\n",
    "print(classified_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import spam_detection\n",
    "\n",
    "user_input = \"you have just won $14000, claim this award here at this link.\"\n",
    "\n",
    "category = 'spam, not spam, unclear'\n",
    "\n",
    "detected_text = spam_detection(input_text=user_input, category=category, explanation=True, model=model)\n",
    "\n",
    "print(detected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER Recoginition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- person: I, you\n",
      "- location: airport\n",
      "- time: 12:00 AM\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import detect_ner\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "ner_tags = 'person, location, date, number, organization, time, money, percent, facility, product, event, language, law, ordinal, misc, quantity, cardinal'\n",
    "\n",
    "detected_tags = detect_ner(input_text=user_input, ner_tags=ner_tags, model=model)\n",
    "print(detected_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: pronoun\n",
      "will: verb\n",
      "meet: verb\n",
      "you: pronoun\n",
      "at: preposition\n",
      "the: determiner\n",
      "airport: noun\n",
      "sharp: adjective\n",
      "12:00: time\n",
      "AM: time\n",
      ".: punctuation\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import detect_pos\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "# you can add more categories here separated by commas (Default: NOUN, 'noun, verb, ..., cashtag_phrase, entity_phrase')\n",
    "pos_tags = 'noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, determiner, cardinal, foreign, number, date, time, ordinal, money, percent, symbol, punctuation, emoticon, hashtag, email, url, mention, phone, ip, cashtag, entity, noun_phrase, verb_phrase, adjective_phrase, adverb_phrase, pronoun_phrase, preposition_phrase, conjunction_phrase, interjection_phrase, determiner_phrase, cardinal_phrase, foreign_phrase, number_phrase, date_phrase, time_phrase, ordinal_phrase, money_phrase, percent_phrase, symbol_phrase, punctuation_phrase, emoticon_phrase, hashtag_phrase, email_phrase, url_phrase, mention_phrase, phone_phrase, ip_phrase, cashtag_phrase, entity_phrase'\n",
    "\n",
    "pos_result = detect_pos(input_text=user_input, pos_tags=pos_tags, model=model)\n",
    "\n",
    "print(pos_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me encontraré contigo en el aeropuerto en punto de las 12:00 AM.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import translate_text\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "source_language = \"english\"\n",
    "\n",
    "target_language = \"spanish\"\n",
    "\n",
    "translation_result = translate_text(user_input, source_language, target_language, model)\n",
    "\n",
    "print(translation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text emphasizes the importance of punctuality by stating a precise meeting time of 12:00 AM at the airport. It conveys a sense of urgency and the expectation of adherence to the stipulated time. However, it lacks additional details about the purpose of the meeting, the location of the airport, or any other relevant information.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import summarize_text\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "summary_length = \"medium\" # short, medium, long\n",
    "\n",
    "summary_result = summarize_text(user_input, summary_length, model)\n",
    "\n",
    "print(summary_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, it is not possible for an ant to kill a lion. Ants are small insects, typically measuring a few millimeters in length, while lions are large predators that can weigh hundreds of kilograms. Even a large colony of ants would be no match for a single lion.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import answer_question\n",
    "\n",
    "question_text = \"Is it possible that an ant can kill a lion?\"\n",
    "\n",
    "answer_result = answer_question(question_text, model=model)\n",
    "\n",
    "print(answer_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world of fable, where joy pervades,\n",
      "A cat and a mouse, the unlikeliest friends,\n",
      "Their hearts entwined, a bond that never ends.\n",
      "\n",
      "The cat, a creature of sleek and silent grace,\n",
      "The mouse, a bundle of furry, whiskered charm,\n",
      "Together they navigate life's every harm.\n",
      "\n",
      "In the kitchen's corner, a shared feast they find,\n",
      "A banquet of crumbs, a culinary delight,\n",
      "Their bellies full, their spirits take flight.\n",
      "\n",
      "They chase each other in playful delight,\n",
      "Through winding corridors, a whirlwind of delight,\n",
      "Their laughter echoing through the still of night.\n",
      "\n",
      "The cat, a protector, a guardian so bold,\n",
      "The mouse, a companion, loyal and true,\n",
      "Their friendship a beacon in the darkest blue.\n",
      "\n",
      "Like ying and yang, their differences blend,\n",
      "A harmony of hearts, a tale without end,\n",
      "The cat and the mouse, friends to the very end.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import generate_text\n",
    "\n",
    "prompt_text = \"poem on a friendship between a cat and a mouse\"\n",
    "\n",
    "generation_length = \"short\"\n",
    "\n",
    "generated_text = generate_text(prompt_text, generation_length, model)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicate: approaching\n",
      "Roles:\n",
      "- Agent: tornado\n",
      "- Theme: city\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import perform_srl\n",
    "\n",
    "user_input = \"tornado is approaching the city, please take shelter\"\n",
    "\n",
    "srl_result = perform_srl(user_input, model)\n",
    "\n",
    "print(srl_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intent Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: Safety_Warning\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import recognize_intent\n",
    "\n",
    "user_input = \"tornado is approaching the city, please take shelter\"\n",
    "\n",
    "intent_result = recognize_intent(user_input, model)\n",
    "\n",
    "print(intent_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraphrasing Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "Both sentences describe the same event (the setting of the sun in the west) in a different way. They both refer to the evening and the direction of the sun, just using different phrasings.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import paraphrasing_detection\n",
    "\n",
    "user_input = ['''The sun sets in the west every evening.''','''Every evening, the sun goes down in the west.''']\n",
    "\n",
    "intent_result = paraphrasing_detection(input_text=user_input, explanation=True, model=model)\n",
    "\n",
    "print(intent_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
